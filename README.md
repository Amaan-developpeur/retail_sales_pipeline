| **Project Title** | **Retail Sales Analytics & Monitoring Pipeline** |
|-----------------------|--------------------------------------------------|
| *An end-to-end local data engineering system â€” automated, observable, and built for business decision intelligence.* |

## Project Overview  

The **Retail Sales Analytics & Monitoring Pipeline** is a fully automated, **local-first data engineering system** designed to simulate how modern retail companies process, monitor, and visualize daily sales performance.

It ingests synthetic retail transactions, validates schemas, transforms raw data into KPI-rich insights, and exposes them via both **API** and **interactive Streamlit dashboard** â€” all powered by **SQLite** and **Python**.

The goal is to showcase **real-world data engineering principles**:  
automation, idempotent ETL, observability, and business-aligned analytics â€” without relying on cloud or paid services.

---

### Highlights
- Built to **mimic real enterprise pipelines**, end-to-end.  
- Uses **automated scheduling (APScheduler)** for daily ETL execution.  
- Provides **real-time health monitoring** and **Slack failure alerts**.  
- Empowers decision-makers with **live dashboards** and **actionable insights**.  
- 100% **local, lightweight, and production-structured** â€” runs anywhere.

## ğŸ’¼ Business Impact  

| ğŸ§© **Business Challenge** | ğŸš€ **Implemented Solution** | ğŸ’¡ **Impact / Outcome** |
|----------------------------|-----------------------------|--------------------------|
| Sales data scattered across CSVs, inconsistent formats | Automated ingestion with schema validation | Centralized, reliable single source of truth |
| Manual daily reporting caused delays | End-to-end ETL pipeline with scheduler automation | Zero manual intervention â€” data updates daily |
| No visibility into real-time performance | Interactive Streamlit dashboard with KPIs and charts | Instant insight into revenue, profit, and trends |
| Undetected schema drift and data errors | Automated monitoring with Slack alerts | Early detection of anomalies before they break reporting |
| No long-term performance trend analysis | Rolling 7-day analytics integrated into dashboard | Consistent visibility into business momentum |
| Poor scalability of ad-hoc scripts | Modular, idempotent pipeline architecture | Extensible and production-like for enterprise scale |

---
## System Architecture  

Below is the complete architecture of the **Retail Sales Analytics & Monitoring Pipeline**, designed to emulate a real-world, production-ready data engineering ecosystem.

```text
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Retail Sales Analytics Pipeline (ETL)  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  [M2] Data Generator (Faker - Synthetic CSVs) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  [M3] Ingestion Layer (Schema Validation)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  [M4] Transformation Layer (KPI Computation) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  [M5] Load Layer (SQLite Warehouse)          â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                                                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ [M6] FastAPI Service          â”‚                   â”‚ [M6] Streamlit Dashboard     â”‚
   â”‚ â†’ `/kpi/revenue`, `/health`   â”‚                   â”‚ â†’ KPIs, Trends, Summary      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ [M7] Scheduler (APScheduler Automation)      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ [M8] Monitoring & Slack Alerts               â”‚
                   â”‚  â†’ Schema Drift | KPI Anomalies | Health     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## Project Structure  

The project follows a **clean, modular directory layout** â€” designed for clarity, maintainability, and real-world scalability.

```text
retail_sales_pipeline/
â”‚
â”‚   .gitignore                 â† ignored files & logs
â”‚   requirements.txt           â† dependency list
â”‚   run_all.py                 â† optional master runner
â”‚   schema_config.json         â† schema definitions for ingestion
â”‚
â”œâ”€â”€â”€dashboard/                 â† Streamlit visualization layer
â”‚       streamlit_app.py
â”‚
â”œâ”€â”€â”€data/                      â† All data lifecycle stages
â”‚   â”‚   product_catalog.csv    â† reference dataset
â”‚   â”‚
â”‚   â”œâ”€â”€â”€raw/                   â† newly generated daily CSVs
â”‚   â”œâ”€â”€â”€ingested/              â† validated and logged files
â”‚   â”œâ”€â”€â”€processed/             â† transformed outputs (transactional + aggregated)
â”‚   â””â”€â”€â”€exchange_rates/        â† unused (kept for optional extensions)
â”‚
â”œâ”€â”€â”€db/                        â† local analytical database
â”‚       retail_sales.db
â”‚
â”œâ”€â”€â”€images/                    â† screenshots for README
â”‚       dashboard_kpis.png
â”‚       dashboard_region_chart.png
â”‚       dashboard_summary.png
â”‚       dashboard_top_products.png
â”‚       monitoring_log.png
â”‚       revenue_trends.png
â”‚       scheduler_run.png
â”‚
â”œâ”€â”€â”€logs/                      â† pipeline & system logs
â”‚       extract_sales.log
â”‚       generate_fake_sales.log
â”‚       load_to_db.log
â”‚       monitoring.log
â”‚       pipeline_health.json
â”‚       scheduler.log
â”‚       transform_sales.log
â”‚
â”œâ”€â”€â”€scripts/                   â† modular ETL and utility scripts
â”‚       alerts.py              â† Slack notification system
â”‚       api_server.py          â† FastAPI endpoints
â”‚       extract_sales.py       â† schema validation + ingestion
â”‚       generate_fake_sales.py â† synthetic data generator
â”‚       load_to_db.py          â† database loading layer
â”‚       monitoring.py          â† drift & anomaly tracking
â”‚       scheduler.py           â† APScheduler automation
â”‚       transform_sales.py     â† KPI enrichment and aggregation
â”‚
â””â”€â”€â”€tests/                     â† placeholder for test scripts

## Core Features  

| Feature | Description |
|----------|--------------|
| **Automated ETL Pipeline** | End-to-end ingestion â†’ transform â†’ load using APScheduler |
| **Schema Validation** | Detects missing or extra columns before ingestion |
| **Data Transformation** | Cleans, enriches, and computes key retail KPIs |
| **SQLite Data Warehouse** | Centralized analytical store for all processed data |
| **FastAPI Service** | Exposes KPIs via REST endpoints (`/kpi/revenue`, `/health`) |
| **Streamlit Dashboard** | Interactive BI interface for KPIs, trends, and insights |
| **Monitoring & Alerts** | Detects schema drift, anomalies, and posts Slack alerts |
| **Rolling 7-Day Analytics** | Replaces forecasting with a lightweight moving average trend |
| **Business Insight Layer** | Auto-generated narrative explaining revenue and margin shifts |

## Key Business KPIs  

| KPI | Purpose |
|-----|----------|
| **Total Revenue** | Overall sales performance metric |
| **Total Profit** | Net profitability from all transactions |
| **Average Margin %** | Efficiency of pricing and cost management |
| **Revenue Growth %** | Daily business momentum indicator |
| **Top Region Contribution %** | Identifies dependency or concentration risk |
| **Low-Margin Product Share %** | Tracks proportion of low-profit SKUs |
| **Rolling 7-Day Average Revenue** | Smooth trendline showing business stability |
| **Business Summary Insights** | Auto-generated one-line recommendations (e.g., growth, risk, margin issues) to guide immediate decisions |

## Dashboard Overview  

The **Streamlit Dashboard** acts as the visualization and decision interface â€” turning clean, processed retail data into **real-time business insights**.  
It connects directly to the SQLite data warehouse and updates dynamically after every ETL run.

---

### KPI Overview  
![Dashboard KPIs](images/dashboard_kpis.png)  
Displays key performance metrics: **Total Revenue, Total Profit, and Average Margin %**.  
These top-line figures give instant visibility into business performance.

---

### Revenue by Region  
![Revenue by Region](images/dashboard_region_chart.png)  
Bar chart comparing **revenue and profit** across regions â€” used to identify strong vs. underperforming markets.

---

### Top Products by Revenue  
![Top Products Table](images/dashboard_top_products.png)  
Shows top-performing SKUs with **revenue, profit, and margin %**, helping the business focus on high-impact products.

---

### Daily Revenue Trend (Rolling Average)  
![Revenue Trends](images/revenue_trends.png)  
Line chart visualizing daily revenue with a **7-day rolling average**, offering a smooth view of sales momentum and performance stability.

---

### Business Summary Insights  
![Business Summary](images/dashboard_summary.png)  
Automatically generated, data-driven **business insights** summarizing the dayâ€™s performance â€”  
e.g., revenue growth, regional dependency risk, and profitability warnings â€” built to support quick decisions.

---

**All visuals update automatically** after every scheduled ETL run, ensuring the dashboard always reflects the latest business state.

---

###  System Logs & Drift Detection  
![Monitoring Log](images/monitoring_log.png)  
Captures every ETL run â€” with transactional row counts, revenue totals, and schema status.

---

###  Automated Scheduler Execution  
![Scheduler Run](images/scheduler_run.png)  
Shows the APScheduler in action â€” running daily ETL jobs and posting Slack alerts on success or failure.

---
## Tech Stack  

| Layer | Tools & Technologies |
|--------|-----------------------|
| **Language** | Python 3.11+ |
| **Data Handling** | Pandas, Faker, NumPy |
| **Database** | SQLite (lightweight local warehouse) |
| **API Layer** | FastAPI + Uvicorn |
| **Dashboard Layer** | Streamlit |
| **Scheduling & Automation** | APScheduler |
| **Monitoring & Alerts** | Slack Webhooks, RotatingFileHandler |
| **Version Control** | Git + GitHub |
| **Environment** | Anaconda / venv (cross-platform) |

## Business Value Summary  

This project demonstrates the **real-world lifecycle of data intelligence** â€”  
from raw retail transactions to decision-ready insights.

It replaces manual reporting and unmonitored scripts with a **fully automated, observable pipeline** that:

- Generates, ingests, and transforms data autonomously.  
- Monitors every run for schema drift and KPI anomalies.  
- Pushes live business insights through a dashboard.  
- Sends instant Slack alerts on failures or performance shifts.  







